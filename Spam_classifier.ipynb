{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = pd.read_csv('spam.csv', encoding = 'latin-1')\n",
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete useless columns from dataframe\n",
    "spam_data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis = 1, inplace = True)\n",
    "\n",
    "# Rename columns v1 and v1 to 'target' and 'text'\n",
    "spam_data.rename(columns = {'v1': 'target', 'v2' : 'text'}, inplace = True)\n",
    "\n",
    "# Change the data in the target variable to be a binary indicator of spam or not spam (ham)\n",
    "spam_data['target'] = np.where(spam_data['target']=='spam',1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  Go until jurong point, crazy.. Available only ...\n",
       "1       0                      Ok lar... Joking wif u oni...\n",
       "2       1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3       0  U dun say so early hor... U c already then say...\n",
       "4       0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into a training and testing set with y representing the target variable \n",
    "# and x representing the feature(s)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data['text'], \n",
    "                                                    spam_data['target'], \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the percentage of the data labeled as spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.406317300789663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shows that the dataset is inbalanced\n",
    "\n",
    "100*len(spam_data[spam_data['target']==1])/len(spam_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a multinomial Naive Bayes model using CountVectorizer to transform the current features (sns text) into a vector of word counts. \n",
    "Since the classes in the data are imbalanced, instead of using the accuracy score of the model which mesures the (true positives + true negativs)/all instances, I'll evaluate the efficiency of the model by calculating the area under the ROC (Reciever Opperating Characteristic) Curve which mesures the false positive vs the true positive rates. The closer to 1, the better the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and fit a naive bayes classifier with parameters alpha = 0.1\n",
    "# the alpha parameter will ensure that the p(word|class) != 0 even if that word \n",
    "# has not previously been encountered by our classifier\n",
    "\n",
    "def naive_bayes():\n",
    "    vect = CountVectorizer().fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    model = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict(vect.transform(X_test))\n",
    "    \n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "    # Sort model coefficients by index value\n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "    \n",
    "    # Return feature names (words) sorted by the sorted coefficient index value and slice top 10 and bottom 10 segments\n",
    "    print('Words least likely to predict spam:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "    print('Words most likely to predict spam: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "    print('ROC_auc Score: {}'.format(roc_auc_score(y_test, predictions)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words least likely to predict spam:\n",
      "['kaiez' 'needy' 'needs' 'needing' 'needed' 'needa' 'ned' 'necklace' 'neck'\n",
      " 'necessity']\n",
      "\n",
      "Words most likely to predict spam: \n",
      "['to' 'call' 'you' 'your' 'free' 'for' 'the' 'now' 'or' 'txt']\n",
      "\n",
      "ROC_auc Score: 0.9720812182741116\n"
     ]
    }
   ],
   "source": [
    "naive_bayes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest coefficients predicted by the model correspond to words which have a higher probability in appearing in a text which is labled as not being spam, whereas the largest coefficients show the opposite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes model using TfidfVectorizer\n",
    "Unlike count vectorizer which uses a 'bag of words' approach to give us word a count frequency as a feature, tfidf (term frequency inverse document frequency) uses a weighting system to determine an individual words importance based on its frequency in a document and the corpus as a whole. The weight will increase due to its frequency in the document but decrease in response to its frequency in the corpus. By this method (as opposed to simply returning  counts of words) tfidf will penalize stop words such as 'the', 'and', and 'a' as these words likely won't be strong indicators of what we're trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def nb_tfidf():\n",
    "    \n",
    "    vect = TfidfVectorizer(min_df=3).fit(X_train)\n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    model = MultinomialNB(alpha=0.1).fit(X_train_vectorized, y_train)\n",
    "    predictions = model.predict(vect.transform(X_test))\n",
    "    \n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "    \n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "    \n",
    "    \n",
    "    print('Words least likely to predict spam:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "    print('words most likely to predict spam: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "\n",
    "    print('ROC_auc Score: {}'.format(roc_auc_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words least likely to predict spam:\n",
      "['ûò' 'hell' 'height' 'hee' 'heavy' 'shower' 'showing' 'head' 'hella' 'he']\n",
      "\n",
      "words most likely to predict spam: \n",
      "['to' 'call' 'free' 'your' 'txt' 'you' 'or' 'for' 'now' 'stop']\n",
      "\n",
      "ROC_auc Score: 0.9416243654822335\n"
     ]
    }
   ],
   "source": [
    "nb_tfidf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance of the model I want to add features to the feature space that serve as strong indicators of whether or not an email is classified as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_spam = spam_data[spam_data.target == 0]\n",
    "spam = spam_data[spam_data.target == 1]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of spam messages: 138.8661311914324\n",
      "Average length of non-spam messages: 71.02362694300518\n"
     ]
    }
   ],
   "source": [
    "spam_text_len = spam.text.str.len().mean()\n",
    "non_spam_text_len = not_spam.text.str.len().mean()\n",
    "print('Average length of spam messages: {}\\nAverage length of non-spam messages: {}'.format(spam_text_len,\n",
    "                                                                                               non_spam_text_len))                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of digets in spam messages: 15.759036144578314\n",
      "Average number of digits in non-spam messages: 0.2992746113989637\n"
     ]
    }
   ],
   "source": [
    "spam_digit_count = spam.text.str.findall(r'\\d').str.len().mean()\n",
    "non_spam_digit_count = not_spam.text.str.findall(r'\\d').str.len().mean()\n",
    "    \n",
    "print('Average number of digets in spam messages: {}\\nAverage number of digits in non-spam messages: {}'.format(spam_digit_count,\n",
    "                                                                                                                        non_spam_digit_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of non-word characters in spam messages: 29.041499330655956\n",
      "Average number of non-word characters in non-spam messages: 17.29181347150259\n"
     ]
    }
   ],
   "source": [
    "no_word_spam = spam.text.str.findall(r'\\W').str.len().mean()\n",
    "no_word_not_spam = not_spam.text.str.findall(r'\\W').str.len().mean()\n",
    "    \n",
    "print('Average number of non-word characters in spam messages: {}\\nAverage number of non-word characters in non-spam messages: {}'.format(no_word_spam, no_word_not_spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are substantial differences between the spam and not spam rows described by the \n",
    "statistics above, these counts would likely make good indicators for our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_feature(X, feature_to_add):\n",
    "    \n",
    "    # Returns sparse feature matrix with added feature.\n",
    "    # feature_to_add can also be a list of features.\n",
    "    \n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the add_feature function to add the above mentioned features to our data, I'll train and fit a logistic regression model and evaluate the roc_auc score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def added_features_log_reg():\n",
    "    vect = CountVectorizer(min_df=5, analyzer = 'char_wb', ngram_range=(2,6)).fit(X_train)\n",
    "    \n",
    "    length_of_doc = X_train.str.len().values\n",
    "    length_of_doc_test = X_test.str.len().values\n",
    "    digit_count = X_train.str.findall(r'\\d').str.len().values\n",
    "    digit_count_test = X_test.str.findall(r'\\d').str.len().values\n",
    "    non_word_char_count = X_train.str.findall(r'\\W').str.len().values\n",
    "    non_word_char_count_test = X_test.str.findall(r'\\W').str.len().values\n",
    "   \n",
    "    X_train_vectorized = vect.transform(X_train)\n",
    "    X_test_vectorized = vect.transform(X_test)\n",
    "    \n",
    "    X_train_vectorized = add_feature(X_train_vectorized, [length_of_doc, \n",
    "                                                          digit_count,\n",
    "                                                         non_word_char_count])\n",
    "    X_test_vectorized = add_feature(X_test_vectorized, [length_of_doc_test, \n",
    "                                                        digit_count_test,\n",
    "                                                       non_word_char_count_test])\n",
    "    \n",
    "    model = LogisticRegression(C=100).fit(X_train_vectorized, y_train)\n",
    "    \n",
    "    predictions = model.predict(X_test_vectorized)\n",
    "    \n",
    "    feature_names = vect.get_feature_names()\n",
    "    \n",
    "    sorted_coef_index = model.coef_[0].argsort()\n",
    "    \n",
    "    feature_names.append('length_of_doc')\n",
    "    feature_names.append('digit_count')\n",
    "    feature_names.append('non_word_char_count')\n",
    "    feature_names = np.array(feature_names)\n",
    "    \n",
    "    print('Words segments least likely to predict spam:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "    print('Words segments most likely to predict spam: \\n{}\\n'.format(feature_names[sorted_coef_index[:-11:-1]]))\n",
    "\n",
    "    print('ROC_auc Score: {}'.format(roc_auc_score(y_test, predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words segments least likely to predict spam:\n",
      "['. ' '..' '? ' ' i' ' y' ' go' ':)' ' h' ' m' 'h ']\n",
      "\n",
      "Words segments most likely to predict spam: \n",
      "['digit_count' 'ne' 'co' 'ia' 'xt' ' ch' 'mob' 'ar' 'ww' ' x']\n",
      "\n",
      "ROC_auc Score: 0.9788593110707434\n"
     ]
    }
   ],
   "source": [
    "added_features_log_reg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Unlike the models trained before which used whole words as features to predict our target variable spam, this model (as a parameter in the count vectorizer function) uses segments of words ranging from 2 to 6 characters long in order to make its predictions. Although this makes interpretation of the words as features more difficult, it also makes the model more robust to spelling errors made by the senders of the messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
